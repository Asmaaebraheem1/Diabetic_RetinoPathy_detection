# -*- coding: utf-8 -*-
"""final_dino_diabetic_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M-gIlOdN3gmp_q11wZb4pd6X3BxeLlgW
"""

# prompt: connect with kaggle

!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d alaahussien/diabetic-eye

# prompt: unzip

!unzip /content/diabetic-eye.zip

import os
os.environ["WANDB_DISABLED"] = "true"

import os
from PIL import Image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from glob import glob

def train_df(tr_path):
    classes, class_paths = zip(*[(label, os.path.join(tr_path, label, image))
                                 for label in os.listdir(tr_path) if os.path.isdir(os.path.join(tr_path, label))
                                 for image in os.listdir(os.path.join(tr_path, label))])

    tr_df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})
    return tr_df

def test_df(ts_path):
    classes, class_paths = zip(*[(label, os.path.join(ts_path, label, image))
                                 for label in os.listdir(ts_path) if os.path.isdir(os.path.join(ts_path, label))
                                 for image in os.listdir(os.path.join(ts_path, label))])

    ts_df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})
    return ts_df

def vall_df(val_path):
    classes, class_paths = zip(*[(label, os.path.join(val_path, label, image))
                                 for label in os.listdir(val_path) if os.path.isdir(os.path.join(val_path, label))
                                 for image in os.listdir(os.path.join(val_path, label))])

    val_df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})
    return val_df

tr_df = train_df('/content/data/training')

tr_df

ts_df = test_df('/content/data/test')

ts_df

val_df = vall_df('/content/data/validation')

val_df

plt.figure(figsize=(15,7))
ax = sns.countplot(data=tr_df , y=tr_df['Class'])

plt.xlabel('')
plt.ylabel('')
plt.title('Count of images in each class', fontsize=20)
ax.bar_label(ax.containers[0])
plt.show()

plt.figure(figsize=(15, 7))
ax = sns.countplot(y=ts_df['Class'])

ax.set(xlabel='', ylabel='', title='Count of images in each class')
ax.bar_label(ax.containers[0])

plt.show()

plt.figure(figsize=(15, 7))
ax = sns.countplot(y=val_df['Class'])

ax.set(xlabel='', ylabel='', title='Count of images in each class')
ax.bar_label(ax.containers[0])

plt.show()

def load_image(img_path):
    return Image.open(img_path).convert("RGB")

img_resolutions = []
for img_path in tr_df['Class Path'] :
    img = load_image(img_path)
    img_resolutions.append(img.size)
img_resolutions = np.array(img_resolutions)

print("Train Dataset")
min_resolution = np.min(img_resolutions, axis=0)
max_resolution = np.max(img_resolutions, axis=0)
mean_resolution = np.mean(img_resolutions, axis=0, dtype=np.int32)
median_resolution = np.median(img_resolutions, axis=0)

print("Minimum image width:", min_resolution[0])
print("Minimum image height:", min_resolution[1])
print("Maximum image width:", max_resolution[0])
print("Maximum image height:", max_resolution[1])
print(f"Mean image resolution: {mean_resolution[0]}x{mean_resolution[1]}")
print(f"Median image resolution: {median_resolution[0]}x{median_resolution[1]}")

img_resolutions = []
for img_path in ts_df['Class Path'] :
    img = load_image(img_path)
    img_resolutions.append(img.size)
img_resolutions = np.array(img_resolutions)

print("Test Dataset")
min_resolution = np.min(img_resolutions, axis=0)
max_resolution = np.max(img_resolutions, axis=0)
mean_resolution = np.mean(img_resolutions, axis=0, dtype=np.int32)
median_resolution = np.median(img_resolutions, axis=0)

print("Minimum image width:", min_resolution[0])
print("Minimum image height:", min_resolution[1])
print("Maximum image width:", max_resolution[0])
print("Maximum image height:", max_resolution[1])
print(f"Mean image resolution: {mean_resolution[0]}x{mean_resolution[1]}")
print(f"Median image resolution: {median_resolution[0]}x{median_resolution[1]}")

img_resolutions = []
for img_path in val_df['Class Path'] :
    img = load_image(img_path)
    img_resolutions.append(img.size)
img_resolutions = np.array(img_resolutions)

print("Validation Dataset")
min_resolution = np.min(img_resolutions, axis=0)
max_resolution = np.max(img_resolutions, axis=0)
mean_resolution = np.mean(img_resolutions, axis=0, dtype=np.int32)
median_resolution = np.median(img_resolutions, axis=0)

print("Minimum image width:", min_resolution[0])
print("Minimum image height:", min_resolution[1])
print("Maximum image width:", max_resolution[0])
print("Maximum image height:", max_resolution[1])
print(f"Mean image resolution: {mean_resolution[0]}x{mean_resolution[1]}")
print(f"Median image resolution: {median_resolution[0]}x{median_resolution[1]}")

import shutil
import os

# Define the source (Kaggle input) and destination (Kaggle working) paths
input_dir = '/content/data'
working_dir = '/content/diabetic'

# Ensure the destination folder exists
os.makedirs(working_dir, exist_ok=True)

# Copy the entire directory from input to working
shutil.copytree(input_dir, working_dir, dirs_exist_ok=True)  # dirs_exist_ok=True will not raise an error if the directory exists

!pip install Augmentor

import Augmentor
import os
import shutil

# Path to the dataset folder containing class subfolders
dataset_path = "/content/diabetic/training"
output_folder_name = "output"

# Target number of images for all classes
target_num_images = 1000

# Loop through each class folder in the dataset path
for class_name in os.listdir(dataset_path):
    class_folder = os.path.join(dataset_path, class_name)

    # Check if it's a directory (class folder)
    if not os.path.isdir(class_folder):
        continue

    # Get the current number of images in the class folder
    current_num_images = len([f for f in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, f))])

    # Determine the number of images needed for this class
    if current_num_images >= target_num_images:
        print(f"Class {class_name} already has {current_num_images} images. No augmentation needed.")
        continue

    num_images_to_generate = target_num_images - current_num_images
    print(f"Processing class: {class_name} - Generating {num_images_to_generate} additional images.")

    # Create Augmentor pipeline for the current class
    p = Augmentor.Pipeline(class_folder)

    # Apply augmentations
    p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)
    p.flip_left_right(probability=0.5)

    # Generate the required number of augmented images
    p.sample(num_images_to_generate)

    # Path to the output folder created by Augmentor
    output_folder = os.path.join(class_folder, output_folder_name)

    # Move the augmented images to the original class folder
    for filename in os.listdir(output_folder):
        src = os.path.join(output_folder, filename)
        dst = os.path.join(class_folder, filename)
        shutil.move(src, dst)  # Move file to the class folder

    # Remove the output folder after moving the images
    shutil.rmtree(output_folder)
    print(f"Completed processing class: {class_name}")

print("Augmentation and file moving process complete.")

tr_df = train_df('/content/diabetic/training')

plt.figure(figsize=(15,7))
ax = sns.countplot(data=tr_df , y=tr_df['Class'])

plt.xlabel('')
plt.ylabel('')
plt.title('Count of images in each class', fontsize=20)
ax.bar_label(ax.containers[0])
plt.show()

import Augmentor
import os
import shutil

# Path to the dataset folder containing class subfolders
dataset_path = "/content/diabetic/test"
output_folder_name = "output"

# Dictionary to specify the number of images to generate for each class
selected_classes = {
    '3': 60,  # Generate 100 augmented images for class "3"
    '4': 85   # Generate 150 augmented images for class "4"
}

# Loop through each class folder in the dataset path
for class_name in os.listdir(dataset_path):
    class_folder = os.path.join(dataset_path, class_name)

    # Skip if the class is not in the selected_classes dictionary
    if class_name not in selected_classes:
        print(f"Skipping class: {class_name}")
        continue

    if os.path.isdir(class_folder):  # Check if it's a directory (class folder)
        print(f"Processing class: {class_name}")

        # Get the number of augmented images for this class
        num_images = selected_classes[class_name]

        # Create Augmentor pipeline for the current class
        p = Augmentor.Pipeline(class_folder)

        # Apply augmentations
        p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)
        p.flip_left_right(probability=0.5)

        # Generate augmented images
        p.sample(num_images)

        # Path to the output folder created by Augmentor
        output_folder = os.path.join(class_folder, output_folder_name)

        # Move the augmented images to the original class folder
        for filename in os.listdir(output_folder):
            src = os.path.join(output_folder, filename)
            dst = os.path.join(class_folder, filename)
            shutil.move(src, dst)  # Move file to the class folder

        # Remove the output folder after moving the images
        shutil.rmtree(output_folder)
        print(f"Completed processing class: {class_name}")

print("Augmentation and file moving process complete.")

te_df = test_df('/content/diabetic/test')

plt.figure(figsize=(15,7))
ax = sns.countplot(data=te_df , y=te_df['Class'])

plt.xlabel('')
plt.ylabel('')
plt.title('Count of images in each class', fontsize=20)
ax.bar_label(ax.containers[0])
plt.show()

import Augmentor
import os
import shutil

# Path to the dataset folder containing class subfolders
dataset_path = "/content/diabetic/validation"
output_folder_name = "output"

# Dictionary to specify the number of images to generate for each class
selected_classes = {
    '3': 60,  # Generate 100 augmented images for class "3"
    '4': 85   # Generate 150 augmented images for class "4"
}

# Loop through each class folder in the dataset path
for class_name in os.listdir(dataset_path):
    class_folder = os.path.join(dataset_path, class_name)

    # Skip if the class is not in the selected_classes dictionary
    if class_name not in selected_classes:
        print(f"Skipping class: {class_name}")
        continue

    if os.path.isdir(class_folder):  # Check if it's a directory (class folder)
        print(f"Processing class: {class_name}")

        # Get the number of augmented images for this class
        num_images = selected_classes[class_name]

        # Create Augmentor pipeline for the current class
        p = Augmentor.Pipeline(class_folder)

        # Apply augmentations
        p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)
        p.flip_left_right(probability=0.5)

        # Generate augmented images
        p.sample(num_images)

        # Path to the output folder created by Augmentor
        output_folder = os.path.join(class_folder, output_folder_name)

        # Move the augmented images to the original class folder
        for filename in os.listdir(output_folder):
            src = os.path.join(output_folder, filename)
            dst = os.path.join(class_folder, filename)
            shutil.move(src, dst)  # Move file to the class folder

        # Remove the output folder after moving the images
        shutil.rmtree(output_folder)
        print(f"Completed processing class: {class_name}")

print("Augmentation and file moving process complete.")

val_df = vall_df('/content/diabetic/validation')

plt.figure(figsize=(15,7))
ax = sns.countplot(data=val_df , y=val_df['Class'])

plt.xlabel('')
plt.ylabel('')
plt.title('Count of images in each class', fontsize=20)
ax.bar_label(ax.containers[0])
plt.show()

import os
import random
import cv2
from matplotlib import pyplot as plt

def show_sample_images(input_dir, num_samples=3):
    for folder in ['training', 'test', 'validation']:
        print(f"--- Showing samples from '{folder}' folder ---")

        folder_path = os.path.join(input_dir, folder)

        # Get all class subfolders
        class_folders = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]

        if not class_folders:
            print(f"No class folders found in '{folder_path}'.")
            continue

        # Create a grid layout for subplots
        fig, axes = plt.subplots(1, num_samples, figsize=(5 * num_samples, 5))
        axes = axes.flatten()  # Flatten axes in case of a 2D grid

        # Randomly select class folders and images
        for i in range(num_samples):
            class_name = random.choice(class_folders)
            class_path = os.path.join(folder_path, class_name)
            images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

            if not images:
                print(f"No images found in '{class_path}'.")
                continue

            image_name = random.choice(images)
            image_path = os.path.join(class_path, image_name)
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Display the image on the corresponding subplot
            ax = axes[i]
            ax.imshow(image_rgb)
            ax.set_title(f"Label: {class_name}")
            ax.axis("off")

        # Adjust layout and show the grid of images
        plt.tight_layout()
        plt.show()

# Define the dataset directory
dataset_directory = "/content/diabetic"  # Replace with your dataset path

# Show sample images
show_sample_images(dataset_directory, num_samples=3)

data_dir = "/content/diabetic"

Name0 = os.listdir(data_dir)
Name0

model_checkpoint = "facebook/dinov2-base"

!pip install datasets

from datasets import load_dataset

dataset = load_dataset('imagefolder',data_dir=data_dir)

dataset['train'].features['label']

dataset  = dataset.shuffle(seed=42)

example = dataset['train'][10]
example

dataset['train'].features

example['image']

example['image'].resize((224,224))

example['label']

labels = dataset['train'].features['label'].names
labels

label2id,id2label = dict(),dict()
for i,label in enumerate(labels):
    label2id[label] = i
    id2label[i] = label
id2label[2]

#prepare raw images for model input
from transformers import AutoImageProcessor

image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)
image_processor

from torchvision.transforms import (
    CenterCrop,
    Compose,
    Normalize,
    RandomHorizontalFlip,
    RandomResizedCrop,
    Resize,
    ToTensor,
)

normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
if "height" in image_processor.size:
    size = (image_processor.size["height"], image_processor.size["width"])
    crop_size = size
    max_size = None
elif "shortest_edge" in image_processor.size:
    size = image_processor.size["shortest_edge"]
    crop_size = (size, size)
    max_size = image_processor.size.get("longest_edge")

train_transforms = Compose(
        [
            RandomResizedCrop(crop_size),
            RandomHorizontalFlip(),
            ToTensor(),
            normalize,
        ]
    )

val_transforms = Compose(
        [
            Resize(size),
            CenterCrop(crop_size),
            ToTensor(),
            normalize,
        ]
    )

test_transforms = Compose(
    [
        Resize(size),
        CenterCrop(size),
        ToTensor(),
        normalize,
    ]
)

def preprocess_train(example_batch):
    """Apply train_transforms across a batch."""
    example_batch["pixel_values"] = [
        train_transforms(image.convert("RGB")) for image in example_batch["image"]
    ]
    return example_batch

def preprocess_val(example_batch):
    """Apply val_transforms across a batch."""
    example_batch["pixel_values"] = [val_transforms(image.convert("RGB")) for image in example_batch["image"]]
    return example_batch
def preprocess_test(example_batch):
    example_batch['pixel_values'] = [val_transforms(image.convert("RGB")) for image in example_batch['image']]
    return example_batch

dataset

splits = dataset['train'].train_test_split(test_size=0.2)

second_split = splits['test'].train_test_split(test_size=0.5)
second_split

train_ds = splits['train']
val_ds= second_split['train']
test_ds = second_split['test']

train_ds.set_transform(preprocess_train)
val_ds.set_transform(preprocess_val)
test_ds.set_transform(preprocess_test)

train_ds[0]

import warnings


from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

model = AutoModelForImageClassification.from_pretrained(
    model_checkpoint,
    label2id=label2id,
    id2label=id2label,
    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint
)
warnings.filterwarnings("ignore")

model_name = model_checkpoint.split('/')[-1]

batch_size=4

args = TrainingArguments(
    f"{model_name}-finetuned-dia_eye",
    remove_unused_columns=False,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=batch_size,
    gradient_accumulation_steps=4,
    per_device_eval_batch_size=batch_size,
    num_train_epochs=10,
    warmup_ratio=0.1,
    logging_steps=10,
    # load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    push_to_hub=False,
)

!pip install evaluate

import evaluate

# Load the accuracy and F1 metrics
accuracy_metric = evaluate.load("accuracy")
f1_metric = evaluate.load("f1")

import numpy as np
def compute_metrics(eval_pred):
    """Computes accuracy, F1 score, and confusion matrix on a batch of predictions."""
    predictions = np.argmax(eval_pred.predictions, axis=1)
    references = eval_pred.label_ids

    # Compute accuracy
    accuracy = accuracy_metric.compute(predictions=predictions, references=references)['accuracy']

    # Compute F1 score
    f1 = f1_metric.compute(predictions=predictions, references=references, average="weighted")['f1']


    return {
        "accuracy": accuracy,
        "f1": f1,
    }

#is used to combine pixel values and their corresponding labels into a batch of data ready for training.
import torch

def collate_fn(examples):
    pixel_values = torch.stack([example['pixel_values'] for example in examples])
    labels = torch.tensor([example['label'] for example in examples])
    return {'pixel_values':pixel_values,'labels':labels}

trainer = Trainer(
    model,
    args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    tokenizer=image_processor,
    compute_metrics=compute_metrics,
    data_collator=collate_fn
)

train_results = trainer.train()

trainer.save_model()
trainer.log_metrics("train", train_results.metrics)
trainer.save_metrics("train", train_results.metrics)
trainer.save_state()

metrics = trainer.evaluate()
trainer.log_metrics('eval',metrics)
trainer.save_metrics("eval",metrics)

outputs = trainer.predict(test_ds)
print(outputs.metrics)

torch.save(model.state_dict(), f='custom_weights.pt')

from huggingface_hub import notebook_login
notebook_login()

trainer.push_to_hub('Diabetic_RetinoPathy_detection')

from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay

y_true = outputs.label_ids
y_pred = outputs.predictions.argmax(1)
labels = train_ds.features['label'].names
cm = confusion_matrix(y_true,y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=labels)
disp.plot(xticks_rotation=45)

from sklearn.metrics import recall_score

recall = recall_score(y_true,y_pred,average=None)
for label,score in zip(labels,recall):
    print(f"Recall for {label}: {score:.2f}")

from sklearn.metrics import precision_score, recall_score, confusion_matrix


# Calculate precision and recall for each class
precision = precision_score(y_true, y_pred, average=None)
recall = recall_score(y_true, y_pred, average=None)

# Calculate specificity for each class
specificities = []
conf_matrix = confusion_matrix(y_true, y_pred, labels=range(len(labels)))
for i, label in enumerate(labels):
    tn = conf_matrix.sum() - (conf_matrix[i, :].sum() + conf_matrix[:, i].sum() - conf_matrix[i, i])
    fp = conf_matrix[:, i].sum() - conf_matrix[i, i]
    specificity = tn / (tn + fp)
    specificities.append(specificity)

# Calculate overall metrics
overall_precision = precision_score(y_true, y_pred, average='weighted')
overall_recall = recall_score(y_true, y_pred, average='weighted')
overall_specificity = np.mean(specificities)  # Average specificity across all classes

# Print overall metrics
print(f"Overall Precision: {overall_precision:.2f}")
print(f"Overall Recall: {overall_recall:.2f}")
print(f"Overall Specificity: {overall_specificity:.2f}")
print("************************************************************************************")

# Print precision, recall, and specificity for each label
for label, prec, rec, spec in zip(labels, precision, recall, specificities):
    print(f"Class '{label}': Precision = {prec:.2f}, Recall = {rec:.2f}, Specificity = {spec:.2f}")

predictions = trainer.predict(test_ds)

# Convert lists back to arrays for plotting
predictions_array = np.array(predictions.predictions)
references_array = np.array(predictions.label_ids)

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Assuming predictions_array contains the probability predictions for each class
# and references_array contains the true labels

# Binarize the output labels for multiclass setting
n_classes = predictions_array.shape[1]
references_array_bin = label_binarize(references_array, classes=range(n_classes))

# Compute ROC curve and AUC for each class
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(references_array_bin[:, i], predictions_array[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute macro-average ROC curve and AUC
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
mean_tpr = np.zeros_like(all_fpr)

for i in range(n_classes):
    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])

mean_tpr /= n_classes
macro_auc = auc(all_fpr, mean_tpr)

# Plot macro-averaged ROC curve
plt.figure()
plt.plot(all_fpr, mean_tpr, color='darkorange', lw=2, label=f'Dino_v2 curve (area = {macro_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('dinov2_auc')
plt.legend(loc="lower right")
plt.show()

# Load model directly
from PIL import Image
import torch
from transformers import AutoImageProcessor, AutoModelForImageClassification

processor = AutoImageProcessor.from_pretrained("AsmaaElnagger/Diabetic_RetinoPathy_detection")
model = AutoModelForImageClassification.from_pretrained("AsmaaElnagger/Diabetic_RetinoPathy_detection")
# Load an image
image_path = "/content/data/test/3/39756_left.jpeg"  # Replace with your image path
image = Image.open(image_path).convert("RGB")  # Ensure it's in RGB format

# Preprocess the image
inputs = processor(images=image, return_tensors="pt") # return pythorch tensor

# Perform inference
with torch.no_grad(): #stop training
    outputs = model(**inputs)

# Get the predicted label
predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
predicted_class = predictions.argmax().item()

# Map the predicted class index to a label
labels = model.config.id2label
predicted_label = labels[predicted_class]

print(f"Predicted label: {predicted_label}")

import os
from PIL import Image
import matplotlib.pyplot as plt
import random
import torch
from transformers import AutoProcessor, AutoModelForImageClassification

# Load the Hugging Face model and processor
model_name = "AsmaaElnagger/Diabetic_RetinoPathy_detection"  # Replace with your model
processor = AutoProcessor.from_pretrained(model_name)
model = AutoModelForImageClassification.from_pretrained(model_name)

# Define the folder path containing subfolders of classes
folder_path = "/content/data/test"  # Replace with your folder path

# Number of images to sample from each class
sample_count = 3

# Dictionary to store results
results = {}

# Collect images and predictions for each class
all_images = []
all_labels = []

for class_name in os.listdir(folder_path):
    class_folder = os.path.join(folder_path, class_name)
    if not os.path.isdir(class_folder):
        continue  # Skip if not a folder

    # Get a list of all images in the class folder
    image_files = [f for f in os.listdir(class_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]

    # Randomly sample images from the class folder
    sampled_files = random.sample(image_files, min(len(image_files), sample_count))

    for file_name in sampled_files:
        image_path = os.path.join(class_folder, file_name)

        try:
            image = Image.open(image_path).convert("RGB")
        except Exception as e:
            print(f"Skipping file {file_name} in class {class_name}: {e}")
            continue

        # Preprocess the image
        inputs = processor(images=image, return_tensors="pt")

        # Perform inference
        with torch.no_grad():
            outputs = model(**inputs)

        # Get predictions
        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
        predicted_class = predictions.argmax().item()
        predicted_label = model.config.id2label[predicted_class]

        # Store the result
        results[image_path] = predicted_label
        all_images.append((image, predicted_label))

# Display images and predictions in a grid
rows = len(all_images) // 3 + 1  # Adjust rows for the grid
cols = 3  # Number of columns
fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))

for idx, (image, label) in enumerate(all_images):
    ax = axes[idx // cols, idx % cols]
    ax.imshow(image)
    ax.axis("off")
    ax.set_title(f"Predicted: {label}")

# Hide empty subplots
for idx in range(len(all_images), rows * cols):
    fig.delaxes(axes[idx // cols, idx % cols])

plt.tight_layout()
plt.show()

all_data=dataset['train']
all_data.set_transform(preprocess_train)



import os
from PIL import Image
import torch
from transformers import AutoProcessor, AutoModelForImageClassification, TrainingArguments, Trainer
from sklearn.metrics import classification_report
 import matplotlib.pyplot as plt
 from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

model_name = "AsmaaElnagger/Diabetic_RetinoPathy_detection"  # Replace with your model
processor = AutoProcessor.from_pretrained(model_name)
model = AutoModelForImageClassification.from_pretrained(model_name)

directories = ["/content/data/validation", "/content/data/tringing", "/content/data/testing"]
true_labels = []
predicted_labels = []

for folder_path in directories:
    for class_name in os.listdir(folder_path):
        class_folder = os.path.join(folder_path, class_name)
        if not os.path.isdir(class_folder):
            continue
        image_files = [f for f in os.listdir(class_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]
        for file_name in image_files:
            image_path = os.path.join(class_folder, file_name)

            try:
                image = Image.open(image_path).convert("RGB")
            except Exception as e:
                print(f"Skipping file {file_name} in class {class_name}: {e}")
                continue

            inputs = processor(images=image, return_tensors="pt")
            with torch.no_grad():
                outputs = model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_class = predictions.argmax().item()
            predicted_label = model.config.id2label[predicted_class]
            true_labels.append(class_name)
            predicted_labels.append(predicted_label)



label_names =all_data.features['label'].names
cm = confusion_matrix(true_labels, predicted_labels)


disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)
disp.plot(xticks_rotation=45, cmap="viridis")
plt.show()